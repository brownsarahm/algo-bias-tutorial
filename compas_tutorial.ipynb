{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fairness in Recidvisim Risk Scores\n",
    "\n",
    "adapted from [BPDM 2017 Tutorial by Caitlin Kuhlman et al](https://github.com/caitlinkuhlman/bpdmtutorial)\n",
    "\n",
    "__Tools:__ Analysis will be done in python, using a number of open source packages commonly used for data science tasks:\n",
    "- __Numpy__ scientific computing. http://www.numpy.org/\n",
    "- __Pandas__ data analysis and manipulation http://pandas.pydata.org/\n",
    "- __Scikit-learn__ machine learning http://scikit-learn.org/stable/\n",
    "- __Matplotlib__ plotting https://matplotlib.org/\n",
    "\n",
    "__Material:__ *Disclaimer*: The analysis presented here is directly inspired by the following references:\n",
    "\n",
    "[1] ProPublica, *“Machine Bias,”* https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing, May 2016.\n",
    "\n",
    "[2] A. Chouldechova. *\"Fair prediction with disparate impact: A study of bias in recidivism prediction instruments.\"* arXiv preprint arXiv:1703.00056 (2017).\n",
    "\n",
    "[3] F. P. Calmon, D. Wei, K. Natesan Ramamurthy, and K. R. Varshney, *“Optimized Data Pre- Processing for Discrimination Prevention,”* arXiv preprint arXiv:1704.03354 (2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load code/tools.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load code/loadcompas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an explanation of the data:\n",
    "\n",
    "* `age`: defendant's age\n",
    "* `c_charge_degree`: degree charged (Misdemeanor of Felony)\n",
    "* `race`: defendant's race\n",
    "* `age_cat`: defendant's age quantized in \"less than 25\", \"25-45\", or \"over 45\"\n",
    "* `score_text`: COMPAS score: 'low'(1 to 5), 'medium' (5 to 7), and 'high' (8 to 10).\n",
    "* `sex`: defendant's gender\n",
    "* `priors_count`: number of prior charges\n",
    "* `days_b_screening_arrest`: number of days between charge date and arrest where defendant was screened for compas score\n",
    "* `decile_score`: COMPAS score from 1 to 10\n",
    "* `is_recid`: if the defendant recidivized\n",
    "* `two_year_recid`: if the defendant within two years\n",
    "* `c_jail_in`: date defendant was imprisoned\n",
    "* `c_jail_out`: date defendant was released from jail\n",
    "* `length_of_stay`: length of jail stay\n",
    "\n",
    "Next we look at the first few rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to look at race, we first look at the counts for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load code/filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the scores, quantized and how they interact as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load code/quant.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load code/recidcorr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation is not that high. Let's measure the disparate impact of the quantized COMPAS score ($\\leq4$ is low, everything else is high) according to the EEOC rule that the values with \"high\" for each protected group should be within 80% of each other. Of course, the interpertation here is not the same, but it's a good starting point.\n",
    "\n",
    "reference: https://en.wikipedia.org/wiki/Disparate_impact#The_80.25_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load code/scoremeans.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load code/diff.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load code/recidmeans.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a difference in recidivism, but not as high as assigned by the COMPAS scores.\n",
    "\n",
    "Now let's measure the difference in scores when we consider both the COMPAS output at true recidivism.\n",
    "\n",
    "We will consider a few different metrics. Further explaination can be found in North Point's response to the ProPublica article, and also in Alexandra Chouldechova’s paper (listed above). The link for it is https://assets.documentcloud.org/documents/2998391/ProPublica-Commentary-Final-070616.pdf . The discussion on error rates and calibration also appear in both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load code/normalize.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each group, the point in the ROC curve corresponds to a $$(\\mbox{false postive rate, true positive rate})$$ pair for a given threshold. In order to caputre the difference in error rates, we map the points to $$\\left(\\frac{\\mbox{false postive rate Afr.-American}}{\\mbox{false postive rate Cauc.}},s \\right)$$\n",
    "and similarly for *false negative* rates for different thersholds s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load code/fpr.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is once again stark. This graph is particlarly concerning due to the significantly higher false positive rates for African Americans across all thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What other diffrences are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load code/decilesdist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load code/decileplot.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load code/priors_dist.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
